---
title: Server-side tools (OpenAI Responses API)
meta:
  title: Server-side tools (OpenAI Responses API) | Tiptap Content AI
  description: Learn how to call tools in the server-side using the OpenAI Responses API.
  category: Content AI
---

This guide explains how to call tools in the server-side using the OpenAI Responses API. It presents an example of a tool that returns the weather in a given location.

First, define the tool in the [OpenAI Responses API tool format](https://platform.openai.com/docs/guides/function-calling?api-mode=responses#defining-functions):

```ts
const weatherTool = {
  type: 'function',
  function: {
    name: 'get_weather',
    description: 'Returns the weather in a given location',
    parameters: {
      type: 'object',
      properties: {
        location: {
          type: 'string',
          description: 'The location to get the weather for',
        },
      },
      required: ['location'],
    },
  },
}
```

Then, when you call the OpenAI API, include the tool in the `tools` array:

```ts
import { AiAgentToolkit } from '@tiptap-pro/extension-ai-agent-server'
import { openaiResponsesAdapter } from '@tiptap-pro/extension-ai-agent'
import OpenAI from 'openai'

const toolkit = new AiAgentToolkit()

// Initialize the OpenAI client
const openai = new OpenAI()

// Call the OpenAI Responses API
const response = await openai.responses.create({
  model: 'gpt-4.1',
  input: [
    {
      role: 'developer',
      content: `
<Your system prompt>
${toolkit.getSystemPrompt()}
`,
    },
    ...llmMessages,
  ],
  // Include the weather tool in the tools array, beside
  // the other tools provided by AiAgentToolkit
  tools: [...toolkit.getTools(openaiResponsesAdapter), weatherTool],
})
```

Then, check if the response contains the weather tool. If so, call the tool and add the result to the `llmMessages` array.

```ts
for (const toolCall of response.output) {
  if (toolCall.type !== 'function_call') {
    continue
  }

  const name = toolCall.name

  if (name !== 'get_weather') {
    continue
  }

  const args = JSON.parse(toolCall.arguments)

  const result = getWeather(args)
  llmMessages.push({
    type: 'function_call_output',
    call_id: toolCall.call_id,
    output: result.toString(),
  })
}
```

Finally, when there are no more server-side tool calls, use the `openaiResponsesAdapter` to convert the response to the format expected by the AI Agent extension.

```ts
const result = openaiResponsesAdapter.parseResponse(response)
```

The `result` should be the response of the API endpoint, and the return value of the `resolver` function.

You can also add chat messages to the `result` describing the tool that was called. This will display the result of the tool call in the chat conversation.

```ts
// Add the tool call message to the beginning of the list of new chat messages
result.chatMessages.unshift({
  type: 'ai',
  text: 'The weather in Berlin is sunny.',
  metadata: {
    // Include this metadata to mark the message as a server-side tool call
    // and display it differently in the UI
    isServerSideToolCall: true,
  },
})
```
